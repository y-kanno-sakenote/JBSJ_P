# -*- coding: utf-8 -*-
"""
è«–æ–‡æ¤œç´¢ï¼ˆçµ±ä¸€UIç‰ˆï¼šãŠæ°—ã«å…¥ã‚Šã«ã‚¿ã‚°ã‚’â€œè¡¨ã§ç›´æ¥å…¥åŠ›â€ï¼‰

æ©Ÿèƒ½:
- ç™ºè¡Œå¹´ãƒ¬ãƒ³ã‚¸ã€å·»ãƒ»å·ï¼ˆè¤‡æ•°é¸æŠï¼‰ã€è‘—è€…ï¼ˆæ­£è¦åŒ–ãƒ»è¤‡æ•°é¸æŠï¼‰ã€å¯¾è±¡ç‰©/ç ”ç©¶ã‚¿ã‚¤ãƒ—ï¼ˆéƒ¨åˆ†ä¸€è‡´ãƒ»è¤‡æ•°é¸æŠï¼‰
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ AND/OR æ¤œç´¢ï¼ˆç©ºç™½/ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€pdf_text ã‚’å«ã‚ã‚‹ã‹é¸æŠå¯èƒ½ï¼‰
- æ¤œç´¢çµæœãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆä¸è¦åˆ—ã®éè¡¨ç¤ºã€HP/PDF ã®ãƒªãƒ³ã‚¯åŒ–ã€â˜…ã§ãŠæ°—ã«å…¥ã‚Šï¼‰
- ãŠæ°—ã«å…¥ã‚Šä¸€è¦§ï¼ˆå¸¸è¨­ãƒ»â˜…ã§è§£é™¤/è¿½åŠ ï¼‰
- ãŠæ°—ã«å…¥ã‚Šã‚¿ã‚°ä»˜ã‘ï¼šãŠæ°—ã«å…¥ã‚Šè¡¨ã®ã€Œtagsã€åˆ—ã‚’ç›´æ¥ç·¨é›†ï¼ˆã‚«ãƒ³ãƒ/ç©ºç™½åŒºåˆ‡ã‚Šï¼‰
- ã€ŒâŒ å…¨ã¦å¤–ã™ã€ãƒœã‚¿ãƒ³ã§ãŠæ°—ã«å…¥ã‚Šä¸€æ‹¬è§£é™¤
"""

import re, time
import pandas as pd
import streamlit as st
from pathlib import Path
from modules.analysis import render_analysis_tab

# ---- try to reuse common filter constants/helpers (no UI/logic change) ----
try:
    from modules.common.filters import (
        TARGET_ORDER as _COMMON_TARGET_ORDER,
        TYPE_ORDER as _COMMON_TYPE_ORDER,
    )
    _HAS_COMMON_FILTERS = True
except Exception:
    _COMMON_TARGET_ORDER = None
    _COMMON_TYPE_ORDER = None
    _HAS_COMMON_FILTERS = False

# optional helper import (best-effort)
try:
    from modules.common.filters import sort_with_order as _common_sort_with_order  # may not exist
except Exception:
    _common_sort_with_order = None
import os

# å—ã‘å–ã‚Š: ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰è‘—è€…ã‚’äº‹å‰åæ˜ 
qp = st.query_params
prefill_author = qp.get("author", None)


# -------------------- ãƒšãƒ¼ã‚¸è¨­å®š --------------------
st.set_page_config(page_title="é†¸é€ å”ä¼šèªŒ è«–æ–‡æ¤œç´¢", layout="wide")

# -------------------- simple auth (local) --------------------
try:
    from modules.common import auth
except Exception:
    auth = None

def _ensure_session_auth():
    if "logged_in" not in st.session_state:
        st.session_state.logged_in = False
    if "username" not in st.session_state:
        st.session_state.username = None

_ensure_session_auth()

# Safe rerun: some Streamlit environments may not allow experimental_rerun()
def _safe_rerun():
    try:
        # experimental_rerun may raise if Streamlit internals change or when
        # called outside a normal session. Guard it to avoid crashing the app.
        st.experimental_rerun()
    except Exception:
        # best-effort: set a flag so UI can reflect the change without raising
        try:
            st.session_state._needs_rerun = True
        except Exception:
            pass

with st.sidebar:
    st.subheader("Login")
    if st.session_state.logged_in:
        st.write(f"Logged in as: {st.session_state.username}")
        if st.button("Logout"):
            st.session_state.logged_in = False
            st.session_state.username = None
            _safe_rerun()
        # --- admin panel: manage users/plans ---
        try:
            if st.session_state.username == "admin":
                st.markdown("---")
                st.subheader("ç®¡ç†ãƒ‘ãƒãƒ«")
                try:
                    users = auth.load_users()
                except Exception:
                    users = {}

                # display simple user list with current plan shown
                user_list = sorted(users.keys())
                # build display labels like: "alice â€” free"
                display_map = {}
                display_opts = ["(é¸æŠã—ã¦ãã ã•ã„)"]
                for u in user_list:
                    plan = users.get(u, {}).get("plan", "free")
                    label = f"{u} â€” {plan}"
                    display_map[label] = u
                    display_opts.append(label)

                sel_label = st.selectbox("ãƒ¦ãƒ¼ã‚¶ãƒ¼é¸æŠ", display_opts, key="_admin_sel_user")
                if sel_label and sel_label != "(é¸æŠã—ã¦ãã ã•ã„)":
                    sel_user = display_map.get(sel_label)
                    cur_plan = auth.get_plan(sel_user)
                    st.write(f"ç¾åœ¨ã® plan: {cur_plan}")
                    col_a, col_b = st.columns([1,1])
                    with col_a:
                        if st.button("Set free", key=f"set_free_{sel_user}"):
                            if auth.set_plan(sel_user, "free"):
                                st.success(f"{sel_user} ã‚’ free ã«è¨­å®šã—ã¾ã—ãŸ")
                                _safe_rerun()
                            else:
                                st.error("æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    with col_b:
                        if st.button("Set paid", key=f"set_paid_{sel_user}"):
                            if auth.set_plan(sel_user, "paid"):
                                st.success(f"{sel_user} ã‚’ paid ã«è¨­å®šã—ã¾ã—ãŸ")
                                _safe_rerun()
                            else:
                                st.error("æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ")

                st.markdown("**æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ **")
                new_user = st.text_input("Username", key="_admin_new_user")
                new_pwd = st.text_input("Password", type="password", key="_admin_new_pwd")
                new_plan = st.selectbox("Plan", ["free","paid"], index=0, key="_admin_new_plan")
                if st.button("Add user", key="_admin_add_user"):
                    if not new_user or not new_pwd:
                        st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    else:
                        ok = auth.add_user(new_user, new_pwd)
                        if ok:
                            # ensure plan set
                            auth.set_plan(new_user, new_plan)
                            st.success(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ {new_user} ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼ˆplan={new_plan}ï¼‰")
                            _safe_rerun()
                        else:
                            st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸ")
        except Exception:
            # guard against auth errors in environments without auth
            pass
    else:
        user = st.text_input("Username", key="_login_user")
        pwd = st.text_input("Password", type="password", key="_login_pwd")
        if st.button("Login"):
            ok = False
            if auth is not None:
                try:
                    ok = auth.verify_user(user, pwd)
                except Exception:
                    ok = False
            if ok:
                st.session_state.logged_in = True
                st.session_state.username = user
                st.success("Login successful")
                _safe_rerun()
            else:
                st.error("Login failed")

if not st.session_state.logged_in:
    st.stop()

# -------------------- ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆï¼ˆè‘—è€…ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³å¼·åŒ–ç‰ˆï¼‰ --------------------
st.markdown(
    """
    <style>
    /* ========= ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ¬„ï¼ˆæ ç·šã‚ã‚Šï¼‰ ========= */
    .stTextInput input, .stNumberInput input, textarea {
      background-color: #e0e0e0 !important;
      color: #000 !important;
      border: 1px solid #666 !important;
      border-radius: 6px !important;
      padding: 4px 8px !important;
    }

    /* ========= Select / MultiSelectï¼ˆå¤–æ ãƒ‡ã‚¶ã‚¤ãƒ³ï¼‰ ========= */
    .stMultiSelect div[data-baseweb="select"],
    .stSelectbox  div[data-baseweb="select"] {
      background-color: #e0e0e0 !important;
      border: 1px solid #666 !important;
      border-radius: 6px !important;
    }
    div[data-baseweb="select"] > div { background: transparent !important; }
    div[data-baseweb="select"] span { color: #000 !important; }
    div[data-baseweb="select"] svg  { color: #000 !important; fill: #000 !important; }

    /* MultiSelect ã®ã‚¿ã‚° */
    div[data-baseweb="tag"] {
      background: #d5d5d5 !important;
      color: #000 !important;
      border-radius: 12px !important;
    }

    /* --- ãƒ•ã‚©ãƒ¼ã‚«ã‚¹æ™‚ã®ã‚¹ã‚¿ã‚¤ãƒ« --- */
    input:focus, textarea:focus,
    .stTextInput input:focus, .stNumberInput input:focus {
      border: 2px solid #1a73e8 !important;
      box-shadow: 0 0 4px #1a73e8 !important;
      outline: none !important;
    }
    .stMultiSelect div[data-baseweb="select"]:focus-within,
    .stSelectbox  div[data-baseweb="select"]:focus-within {
      border: 2px solid #1a73e8 !important;
      box-shadow: 0 0 4px #1a73e8 !important;
    }
    .stMultiSelect input:focus,
    .stSelectbox  input:focus {
      border: none !important;
      box-shadow: none !important;
      outline: none !important;
    }

    /* ======== ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ï¼ˆå€™è£œãƒªã‚¹ãƒˆï¼‰ã‚’â€œé«˜ã & å¤ªã„ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«â€ã« ======== */
    ul[role="listbox"] {
      background: #f5f5f5 !important;
      border: 1px solid #666 !important;
      max-height: 70vh !important;
      min-height: 360px !important;
      overflow-y: auto !important;
      padding-right: 6px !important;
      scrollbar-width: auto;
      scrollbar-color: #555 #e9e9e9;
    }
    li[role="option"] {
      padding: 8px 12px !important;
      line-height: 1.4 !important;
      font-size: 0.95rem !important;
    }
    li[role="option"]:hover,
    li[role="option"][aria-selected="true"] {
      background: #e0e0e0 !important;
      color: #000 !important;
    }

    /* WebKit ç³»ï¼ˆChrome/Edge/Safariï¼‰ã®ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒãƒ¼ */
    ul[role="listbox"]::-webkit-scrollbar { width: 16px; }
    ul[role="listbox"]::-webkit-scrollbar-track { background: #e9e9e9; border-radius: 8px; }
    ul[role="listbox"]::-webkit-scrollbar-thumb { background: #555; border-radius: 8px; border: 3px solid #e9e9e9; }
    ul[role="listbox"]::-webkit-scrollbar-thumb:hover { background: #333; }
    </style>
    """,
    unsafe_allow_html=True
)

# -------------------- å®šæ•° --------------------
KEY_COLS = [
    "llm_keywords","primary_keywords","secondary_keywords","featured_keywords",
    "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰4","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰5",
    "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰6","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰7","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰8","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰9","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰10",
]
BASE_COLS = [
    "No.","ç›¸å¯¾PASS","ç™ºè¡Œå¹´","å·»æ•°","å·æ•°","é–‹å§‹ãƒšãƒ¼ã‚¸","çµ‚äº†ãƒšãƒ¼ã‚¸",
    "è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«","è‘—è€…","file_name","HPãƒªãƒ³ã‚¯å…ˆ","PDFãƒªãƒ³ã‚¯å…ˆ",
    "å¯¾è±¡ç‰©_top3","ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3",
    "llm_keywords","primary_keywords","secondary_keywords","featured_keywords",
]
# çµ±ä¸€å®šç¾©ï¼ˆå­˜åœ¨ã™ã‚Œã° common/filters ã®é †åºã‚’ä½¿ç”¨ï¼‰
TARGET_ORDER = _COMMON_TARGET_ORDER or [
    "æ¸…é…’","ãƒ“ãƒ¼ãƒ«","ãƒ¯ã‚¤ãƒ³","ç„¼é…","ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«é£²æ–™","ç™ºé…µä¹³ãƒ»ä¹³è£½å“",
    "é†¤æ²¹","å‘³å™Œ","ç™ºé…µé£Ÿå“","è¾²ç”£ç‰©ãƒ»æœå®Ÿ","å‰¯ç”£ç‰©ãƒ»ãƒã‚¤ã‚ªãƒã‚¹","é…µæ¯ãƒ»å¾®ç”Ÿç‰©","ã‚¢ãƒŸãƒé…¸ãƒ»ã‚¿ãƒ³ãƒ‘ã‚¯è³ª","ãã®ä»–"
]
TYPE_ORDER = _COMMON_TYPE_ORDER or [
    "å¾®ç”Ÿç‰©ãƒ»éºä¼å­é–¢é€£","é†¸é€ å·¥ç¨‹ãƒ»è£½é€ æŠ€è¡“","å¿œç”¨åˆ©ç”¨ãƒ»é£Ÿå“é–‹ç™º","æˆåˆ†åˆ†æãƒ»ç‰©æ€§è©•ä¾¡",
    "å“è³ªè©•ä¾¡ãƒ»å®˜èƒ½è©•ä¾¡","æ­´å²ãƒ»æ–‡åŒ–ãƒ»çµŒæ¸ˆ","å¥åº·æ©Ÿèƒ½ãƒ»æ „é¤ŠåŠ¹æœ","çµ±è¨ˆè§£æãƒ»ãƒ¢ãƒ‡ãƒ«åŒ–",
    "ç’°å¢ƒãƒ»ã‚µã‚¹ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£","ä¿å­˜ãƒ»å®‰å®šæ€§","ãã®ä»–ï¼ˆç ”ç©¶ã‚¿ã‚¤ãƒ—ï¼‰"
]

# -------------------- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ --------------------
def norm_space(s: str) -> str:
    s = str(s or "")
    s = s.replace("\u00A0", " ")
    return re.sub(r"\s+", " ", s).strip()

def norm_key(s: str) -> str:
    return norm_space(s).lower()

AUTHOR_SPLIT_RE = re.compile(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ]+")
def split_authors(cell):
    if not cell: return []
    return [w.strip() for w in AUTHOR_SPLIT_RE.split(str(cell)) if w.strip()]

def split_multi(s):
    if not s: return []
    return [w.strip() for w in re.split(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ\sã€€]+", str(s)) if w.strip()]

def tokens_from_query(q):
    q = norm_key(q)
    return [t for t in re.split(r"[ ,ï¼Œã€ï¼›;ã€€]+", q) if t]


def ensure_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df

def consolidate_authors_column(df: pd.DataFrame) -> pd.DataFrame:
    """è‘—è€…åˆ—ï¼šç©ºç™½ã§ã¯åˆ†å‰²ã›ãšã€åŒºåˆ‡ã‚Šè¨˜å·ã®ã¿ã§åˆ†å‰²â†’åŒåç•°è¡¨è¨˜ã‚’ä»£è¡¨è¡¨è¨˜ã«çµ±åˆ"""
    if "è‘—è€…" not in df.columns:
        return df
    df = df.copy()
    def unify(cell: str) -> str:
        names = split_authors(cell)
        seen = set()
        result = []
        for n in names:
            k = norm_key(n)
            if not k or k in seen:
                continue
            seen.add(k)
            result.append(n)
        return ", ".join(result)
    df["è‘—è€…"] = df["è‘—è€…"].astype(str).apply(unify)
    return df

def build_author_candidates(df: pd.DataFrame):
    rep = {}
    for v in df.get("è‘—è€…", pd.Series(dtype=str)).fillna(""):
        for name in split_authors(v):
            k = norm_key(name)
            if k and k not in rep:
                rep[k] = name
    return [rep[k] for k in sorted(rep.keys())]

def haystack(row):
    parts = [
        str(row.get("è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«","")),
        str(row.get("è‘—è€…","")),
        str(row.get("file_name","")),
        " ".join(str(row.get(c,"")) for c in KEY_COLS if c in row),
    ]
    return norm_key(" \n ".join(parts))

def to_int_or_none(x):
    try: return int(str(x).strip())
    except Exception:
        m = re.search(r"\d+", str(x))
        return int(m.group()) if m else None

def order_by_template(values, template):
    """
    1) ãƒ†ãƒ³ãƒ—ãƒ¬ã®é † 2) æœªåè¼‰ã¯ã‚¢ãƒ«ãƒ•ã‚¡é † 3) ãã®ä»–ã¯æœ€å¾Œ
    â€» modules.common.filters ã« sort_with_order ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆä½¿ç”¨ï¼ˆè¦‹ãŸç›®ã®é †åºã¯åŒã˜ï¼‰
    """
    # best-effort: use shared sorter if present (keeps UI order identical)
    if _common_sort_with_order is not None:
        try:
            return _common_sort_with_order(list(dict.fromkeys(values)), template)
        except Exception:
            pass
    vs = list(dict.fromkeys(values))
    tmpl_set = set(template)
    head = [v for v in template if v in vs and "ãã®ä»–" not in v]
    mid  = sorted([v for v in vs if v not in tmpl_set and "ãã®ä»–" not in v])
    tail = [v for v in template if v in vs and "ãã®ä»–" in v] + \
           [v for v in vs if ("ãã®ä»–" in v and v not in template)]
    return head + mid + tail

def make_visible_cols(df: pd.DataFrame) -> list[str]:
    """df ã®åˆ—ã‹ã‚‰ã€ç›¸å¯¾PASS/çµ‚äº†ãƒšãƒ¼ã‚¸/file_path/num_pages/file_nameã€ã¨
       ã€llm_keywords ä»¥é™ã®å…¨åˆ—ã€ã‚’éè¡¨ç¤ºå¯¾è±¡ã«ã—ã¦ã€è¡¨ç¤ºåˆ—ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
    """
    base_hide = {"ç›¸å¯¾PASS", "çµ‚äº†ãƒšãƒ¼ã‚¸", "file_path", "num_pages", "file_name"}
    cols = [str(c) for c in df.columns]
    hide = set(c for c in cols if c in base_hide)
    if "llm_keywords" in cols:
        idx = cols.index("llm_keywords")
        hide.update(cols[idx:])
    return [c for c in cols if c not in hide]

def make_row_id(row):
    no = str(row.get("No.", "")).strip()
    if no and no.lower() not in {"none", "nan"}:
        return f"NO:{no}"
    ttl = str(row.get("è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«", "")).strip()
    yr  = str(row.get("ç™ºè¡Œå¹´", "")).strip()
    return f"T:{ttl}|Y:{yr}"

# -------------------- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ --------------------
st.title("é†¸é€ å”ä¼šèªŒã€€è«–æ–‡æ¤œç´¢ Î²_3.0")

DEMO_CSV_PATH = Path("data/keywords_summary5.csv")   # ãƒ¡ã‚¤ãƒ³CSV
SUMMARY_CSV_PATH = Path("data/summaries.csv")         # â† è¿½åŠ : summary
AUTHORS_CSV_PATH = Path("data/authors_readings.csv")  # â† è¿½åŠ : è‘—è€…èª­ã¿


@st.cache_data(ttl=600, show_spinner=False)
def load_local_csv(path: Path) -> pd.DataFrame:
    return ensure_cols(pd.read_csv(path, encoding="utf-8"))


# --- è¿½åŠ ï¼šsummaries.csv ãƒ­ãƒ¼ãƒ€ ---
@st.cache_data(ttl=600, show_spinner=False)
def load_summaries(path: Path) -> pd.DataFrame | None:
    try:
        if not path.exists():
            return None
        df_s = pd.read_csv(path, encoding="utf-8")
        df_s.columns = [str(c).strip() for c in df_s.columns]
        if not {"file_name", "summary"}.issubset(df_s.columns):
            return None
        return df_s[["file_name", "summary"]]
    except Exception:
        return None

# --- è¿½åŠ ï¼šauthors_readings.csv ãƒ­ãƒ¼ãƒ€ ---
@st.cache_data(ttl=600, show_spinner=False)
def load_authors_readings(path: Path) -> pd.DataFrame | None:
    try:
        if not path.exists():
            return None
        adf = pd.read_csv(path, encoding="utf-8")
        adf.columns = [str(c).strip() for c in adf.columns]
        if not {"author", "reading"}.issubset(adf.columns):
            return None
        adf["author"]  = adf["author"].astype(str).str.strip()
        adf["reading"] = adf["reading"].astype(str).str.strip()
        adf = adf[(adf["author"]!="") & (adf["reading"]!="")]
        adf = adf.drop_duplicates(subset=["reading"], keep="first")
        return adf
    except Exception:
        return None

# -------------------- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆå›ºå®šï¼šåŒæ¢±CSVï¼‰ --------------------
df = None
if DEMO_CSV_PATH.exists():
    df = load_local_csv(DEMO_CSV_PATH)
    st.caption(f"âœ… ãƒ‡ãƒ¢CSVã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {DEMO_CSV_PATH}")
else:
    st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {DEMO_CSV_PATH}")
    st.stop()
# --- summary ã‚’ãƒãƒ¼ã‚¸ ---
sum_df = load_summaries(SUMMARY_CSV_PATH)
if sum_df is not None:
    df = df.merge(sum_df, on="file_name", how="left")

 # ===================== ã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆ =====================
tab_search, tab_analysis = st.tabs(["ğŸ” æ¤œç´¢", "ğŸ“Š åˆ†æ"])

# æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯æœ¬ç•ªã§ã¯å¸¸æ™‚ONï¼ˆUIã¯å»ƒæ­¢ï¼‰
use_disk_cache = True

with tab_search:
    # -------------------- æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆåˆ†æã‚¿ãƒ–ã¨é †åºã‚’æƒãˆã‚‹ï¼‰ --------------------
    # 1æ®µç›®ï¼šç™ºè¡Œå¹´ãƒ»å¯¾è±¡ç‰©ãƒ»ç ”ç©¶ã‚¿ã‚¤ãƒ—
    st.subheader("æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿")
    year_vals = pd.to_numeric(df.get("ç™ºè¡Œå¹´", pd.Series(dtype=str)), errors="coerce")
    if year_vals.notna().any():
        ymin_all, ymax_all = int(year_vals.min()), int(year_vals.max())
    else:
        ymin_all, ymax_all = 1980, 2025

    row1_y, row1_tg, row1_tp = st.columns([1.0, 1.2, 1.2])
    with row1_y:
        y_from, y_to = st.slider(
            "ç™ºè¡Œå¹´ï¼ˆç¯„å›²ï¼‰", min_value=ymin_all, max_value=ymax_all,
            value=(ymin_all, ymax_all)
        )
    with row1_tg:
        raw_targets = {t for v in df.get("å¯¾è±¡ç‰©_top3", pd.Series(dtype=str)).fillna("") for t in split_multi(v)}
        targets_all = order_by_template(list(raw_targets), TARGET_ORDER)
        targets_sel = st.multiselect("å¯¾è±¡ç‰©ã§çµã‚Šè¾¼ã¿", targets_all, default=[])
    with row1_tp:
        raw_types = {t for v in df.get("ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3", pd.Series(dtype=str)).fillna("") for t in split_multi(v)}
        types_all = order_by_template(list(raw_types), TYPE_ORDER)
        types_sel = st.multiselect("ç ”ç©¶ã‚¿ã‚¤ãƒ—ã§çµã‚Šè¾¼ã¿", types_all, default=[])

    # 2æ®µç›®ï¼šè‘—è€…ãƒ»è‘—è€…ã‚¤ãƒ‹ã‚·ãƒ£ãƒ«é¸æŠ
    col_author, col_initial = st.columns([1.5, 2])
    with col_initial:
        initials = ["ã™ã¹ã¦","ã‚","ã‹","ã•","ãŸ","ãª","ã¯","ã¾","ã‚„","ã‚‰","ã‚","è‹±å­—"]
        if "author_initial" not in st.session_state:
            st.session_state.author_initial = "ã™ã¹ã¦"
        st.radio(
            "è‘—è€…ã‚¤ãƒ‹ã‚·ãƒ£ãƒ«é¸æŠ",
            options=initials,
            horizontal=True,
            key="author_initial",
        )
    ini = st.session_state["author_initial"]
    with col_author:
        adf = load_authors_readings(AUTHORS_CSV_PATH)
        if adf is not None and not adf.empty:
            cand = adf.copy()
            GOJUON = {
                "ã‚": "ã‚ã„ã†ãˆãŠ",
                "ã‹": "ã‹ããã‘ã“ãŒããã’ã”",
                "ã•": "ã•ã—ã™ã›ãã–ã˜ãšãœã",
                "ãŸ": "ãŸã¡ã¤ã¦ã¨ã ã¢ã¥ã§ã©",
                "ãª": "ãªã«ã¬ã­ã®",
                "ã¯": "ã¯ã²ãµã¸ã»ã°ã³ã¶ã¹ã¼ã±ã´ã·ãºã½",
                "ã¾": "ã¾ã¿ã‚€ã‚ã‚‚",
                "ã‚„": "ã‚„ã‚†ã‚ˆ",
                "ã‚‰": "ã‚‰ã‚Šã‚‹ã‚Œã‚",
                "ã‚": "ã‚ã‚’ã‚“",
            }
            def kata_to_hira(s: str) -> str:
                out = []
                for ch in str(s or ""):
                    o = ord(ch)
                    if 0x30A1 <= o <= 0x30F6:
                        out.append(chr(o - 0x60))
                    else:
                        out.append(ch)
                return "".join(out)
            def hira_head(s: str) -> str | None:
                s = str(s or "");  return kata_to_hira(s)[0] if s else None
            def is_roman_head(s: str) -> bool:
                return bool(re.match(r"[A-Za-z]", str(s or "")))

            if ini == "è‹±å­—":
                cand = cand[cand["reading"].astype(str).str.match(r"[A-Za-z]")]
            elif ini != "ã™ã¹ã¦":
                allowed = set(GOJUON.get(ini, ""))
                cand = cand[cand["reading"].apply(
                    lambda s: (not is_roman_head(s)) and (hira_head(s) in allowed if hira_head(s) else False)
                )]

            AIUEO_ORDER = "ã‚ã„ã†ãˆãŠã‹ããã‘ã“ã•ã—ã™ã›ããŸã¡ã¤ã¦ã¨ãªã«ã¬ã­ã®ã¯ã²ãµã¸ã»ã¾ã¿ã‚€ã‚ã‚‚ã‚„ã‚†ã‚ˆã‚‰ã‚Šã‚‹ã‚Œã‚ã‚ã‚’ã‚“"
            def sort_tuple(reading: str):
                if not reading: return (3, 999, "")
                ch = reading[0]
                if re.match(r"[A-Za-z]", ch): return (2, 999, ch.lower())
                if re.match(r"[\u30A0-\u30FF]", ch): return (1, 999, reading)
                idx = AIUEO_ORDER.find(ch)
                return (0, idx if idx != -1 else 998, reading)

            cand = cand.assign(
                _grp=[sort_tuple(r)[0] for r in cand["reading"]],
                _key=[sort_tuple(r)[1] for r in cand["reading"]],
                _sub=[sort_tuple(r)[2] for r in cand["reading"]],
            ).sort_values(by=["_grp","_key","_sub"], kind="mergesort").drop(columns=["_grp","_key","_sub"])

            reading2author = dict(zip(cand["reading"], cand["author"]))
            options_readings = list(reading2author.keys())
            authors_sel_readings = st.multiselect(
                "è‘—è€…ï¼ˆèª­ã¿ã§æ¤œç´¢å¯ / è¡¨ç¤ºã¯æ¼¢å­—ï¼‹èª­ã¿ï¼‰",
                options=options_readings,
                format_func=lambda r: f"{reading2author.get(r, r)}ï½œ{r}",
                placeholder="ä¾‹ï¼šã‚„ã¾ã  / ã•ã¨ã† / ãŸã‹ã¯ã— ..."
            )
            authors_sel = sorted({reading2author[r] for r in authors_sel_readings}) if authors_sel_readings else []
        else:
            authors_all = build_author_candidates(df)
            authors_sel = st.multiselect("è‘—è€…", authors_all, default=[])

    if 'authors_sel' not in locals(): authors_sel = []
    if 'targets_sel' not in locals(): targets_sel = []
    if 'types_sel'   not in locals(): types_sel   = []

    # 3æ®µç›®ï¼šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    kw_row1, kw_row2 = st.columns([3, 1])
    with kw_row1:
        # keep kw_query in session to allow other UI elements to update it safely
        if "kw_query_input" not in st.session_state:
            st.session_state["kw_query_input"] = ""
        # bind the text_input to a stable session-state key (avoids modifying session_state after widget init)
        st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆç©ºç™½/ã‚«ãƒ³ãƒã§è¤‡æ•°å¯ï¼‰", value=st.session_state.get("kw_query_input", ""), key="kw_query_input")
        kw_query = st.session_state.get("kw_query_input", "")
    with kw_row2:
        kw_mode = st.radio("ä¸€è‡´æ¡ä»¶", ["OR", "AND"], index=0, horizontal=True, key="kw_mode")

    # -------------------- ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ --------------------
    def apply_filters(_df: pd.DataFrame) -> pd.DataFrame:
        df2 = _df.copy()
        if "ç™ºè¡Œå¹´" in df2.columns:
            y = pd.to_numeric(df2["ç™ºè¡Œå¹´"], errors="coerce")
            df2 = df2[(y >= y_from) & (y <= y_to) | y.isna()]
        if authors_sel and "è‘—è€…" in df2.columns:
            sel = {norm_key(a) for a in authors_sel}
            def hit_author(v): return any(norm_key(x) in sel for x in split_authors(v))
            df2 = df2[df2["è‘—è€…"].apply(hit_author)]
        if targets_sel and "å¯¾è±¡ç‰©_top3" in df2.columns:
            t_norm = [norm_key(t) for t in targets_sel]
            df2 = df2[df2["å¯¾è±¡ç‰©_top3"].apply(lambda v: any(t in norm_key(v) for t in t_norm))]
        if types_sel and "ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3" in df2.columns:
            t_norm = [norm_key(t) for t in types_sel]
            df2 = df2[df2["ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3"].apply(lambda v: any(t in norm_key(v) for t in t_norm))]
        toks = tokens_from_query(kw_query)
        if toks:
            def hit_kw(row):
                hs = haystack(row)
                return all(t in hs for t in toks) if kw_mode == "AND" else any(t in hs for t in toks)
            df2 = df2[df2.apply(hit_kw, axis=1)]
        return df2

    filtered = apply_filters(df)

    # -------------------- å‡ºå…¸ãƒ»å†ç¾æ€§ç”¨ã®ä¸€è¡ŒãƒãƒŠãƒ¼ï¼ˆæ¤œç´¢ã‚¿ãƒ–ç”¨ï¼‰ --------------------
    def _render_provenance_banner(total_n: int,
                                  filtered_n: int,
                                  y_from: int, y_to: int,
                                  authors: list[str] | None = None,
                                  targets: list[str] | None = None,
                                  types: list[str] | None = None,
                                  kw_query: str | None = None,
                                  kw_mode: str = "OR") -> None:
        """
        ã‚¿ãƒ–ä¸Šéƒ¨ã«è»½é‡ã®å…±é€šæ³¨è¨˜ï¼ˆå‡ºå…¸ï¼‹é©ç”¨æ¡ä»¶ï¼‰ã‚’1è¡Œã§è¡¨ç¤ºã€‚
        ç©ºã®è¦ç´ ã¯è‡ªå‹•çš„ã«çœç•¥ã€‚
        """
        parts = [f"å‡ºå…¸ï¼šJBSJ DBï¼ˆN={filtered_n} / {total_n}ï¼‰", f"æœŸé–“ï¼š{y_from}â€“{y_to}"]

        def _fmt_list(name: str, vals: list[str] | None, max_items: int = 6) -> None:
            if not vals:
                return
            vs = [str(v) for v in vals if str(v).strip()]
            if not vs:
                return
            txt = ", ".join(vs[:max_items]) + (" â€¦" if len(vs) > max_items else "")
            parts.append(f"{name}ï¼š{txt}")

        _fmt_list("å¯¾è±¡ç‰©", targets)
        _fmt_list("ç ”ç©¶ã‚¿ã‚¤ãƒ—", types)
        _fmt_list("è‘—è€…", authors)

        if kw_query and kw_query.strip():
            q = "ã€".join([t for t in re.split(r"[ ,ï¼Œã€ï¼›;ã€€]+", kw_query.strip()) if t])
            if q:
                parts.append(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ{kw_mode}ï¼‰ï¼š{q}")

        line = " ï½œ ".join(parts)

        st.caption(
            f"{line}",
        )

    _render_provenance_banner(
        total_n=len(df),
        filtered_n=len(filtered),
        y_from=y_from, y_to=y_to,
        authors=authors_sel or [],
        targets=targets_sel or [],
        types=types_sel or [],
        kw_query=kw_query,
        kw_mode=kw_mode
    )

#    # -------------------- æ¤œç´¢çµæœãƒ†ãƒ¼ãƒ–ãƒ« --------------------
    st.markdown(f"### æ¤œç´¢çµæœï¼ˆ{len(filtered):,}ä»¶ï¼‰")

    visible_cols = make_visible_cols(filtered)
    if "è‘—è€…" in visible_cols and "summary" in filtered.columns:
        idx = visible_cols.index("è‘—è€…")
        if "summary" not in visible_cols:
            visible_cols.insert(idx + 1, "summary")

    disp = filtered.loc[:, visible_cols].copy()
    # Ensure çµ‚äº†ãƒšãƒ¼ã‚¸ is available for display even if make_visible_cols hid it
    if "çµ‚äº†ãƒšãƒ¼ã‚¸" in filtered.columns and "çµ‚äº†ãƒšãƒ¼ã‚¸" not in disp.columns:
        disp["çµ‚äº†ãƒšãƒ¼ã‚¸"] = filtered["çµ‚äº†ãƒšãƒ¼ã‚¸"]
    disp["_row_id"] = disp.apply(make_row_id, axis=1)

    # è¡¨ç¤ºç”¨ã«ç™ºè¡Œå¹´ã®ã‚«ãƒ³ãƒ(,)ã‚’é™¤å»ï¼ˆä¾‹: "1,988" -> "1988"ï¼‰
    if "ç™ºè¡Œå¹´" in disp.columns:
        try:
            disp["ç™ºè¡Œå¹´"] = disp["ç™ºè¡Œå¹´"].astype(str).str.replace(",", "").str.strip()
        except Exception:
            pass

    if "favs" not in st.session_state:
        st.session_state.favs = set()
    if "fav_tags" not in st.session_state:
        st.session_state.fav_tags = {}

    disp["â˜…"] = disp["_row_id"].apply(lambda rid: rid in st.session_state.favs)

    # åˆ—åä¿®æ­£ï¼ˆé–‹å§‹ãƒšãƒ¼ã‚¸ â†’ p.å§‹ / çµ‚äº†ãƒšãƒ¼ã‚¸ â†’ p.çµ‚ï¼‰
    rename_map = {}
    if "é–‹å§‹ãƒšãƒ¼ã‚¸" in disp.columns:
        rename_map["é–‹å§‹ãƒšãƒ¼ã‚¸"] = "p.å§‹"
    if "çµ‚äº†ãƒšãƒ¼ã‚¸" in disp.columns:
        rename_map["çµ‚äº†ãƒšãƒ¼ã‚¸"] = "p.çµ‚"
    if rename_map:
        disp = disp.rename(columns=rename_map)

    # LinkColumn è¨­å®šï¼ˆHP/PDF ã‚’çŸ­ã„è¦‹å‡ºã—ã§ï¼‰
    column_config = {
        "â˜…": st.column_config.CheckboxColumn("â˜…", help="æ°—ã«ãªã‚‹è«–æ–‡ã«ãƒã‚§ãƒƒã‚¯/è§£é™¤", default=False, width="small"),
    }
    if "HPãƒªãƒ³ã‚¯å…ˆ" in disp.columns:
        column_config["HPãƒªãƒ³ã‚¯å…ˆ"] = st.column_config.LinkColumn("HP", help="å¤–éƒ¨ã‚µã‚¤ãƒˆã¸ç§»å‹•", display_text="HP")
    if "PDFãƒªãƒ³ã‚¯å…ˆ" in disp.columns:
        column_config["PDFãƒªãƒ³ã‚¯å…ˆ"] = st.column_config.LinkColumn("PDF", help="PDFã‚’é–‹ã", display_text="PDF")

    # åˆ—é †ï¼šã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆé †ã«åˆã‚ã›ã‚‹
    desired_front = ["â˜…", "No.", "HPãƒªãƒ³ã‚¯å…ˆ", "PDFãƒªãƒ³ã‚¯å…ˆ", "ç™ºè¡Œå¹´", "å·»æ•°", "å·æ•°", "p.å§‹", "p.çµ‚"]
    # include only those that exist in disp
    front = [c for c in desired_front if c in disp.columns]
    rest = [c for c in disp.columns if c not in set(front) and c != "_row_id"]
    display_order = front + rest + ["_row_id"]

    with st.form("main_table_form", clear_on_submit=False):
        # (per-row immediate toggle removed â€” keep session-only checkboxes in the table)
        edited_main = st.data_editor(
            disp[display_order],
            key="main_editor",
            use_container_width=True,
            hide_index=True,
            column_config=column_config,
            disabled=[c for c in display_order if c != "â˜…"],
            height=520,
            num_rows="fixed",
        )
        apply_main = st.form_submit_button("ãƒã‚§ãƒƒã‚¯ã—ãŸè«–æ–‡ã‚’ãŠæ°—ã«å…¥ã‚Šãƒªã‚¹ãƒˆã«è¿½åŠ ", use_container_width=True)

    if apply_main:
        subset_ids_main = set(disp["_row_id"].tolist())
        checked_subset_main = set(edited_main.loc[edited_main["â˜…"] == True, "_row_id"].tolist())
        st.session_state.favs = (st.session_state.favs - subset_ids_main) | checked_subset_main

    # --- ãŠæ°—ã«å…¥ã‚Šä¸€è¦§ãƒ˜ãƒƒãƒ€ãƒ¼ï¼‹å…¨å¤–ã—ãƒœã‚¿ãƒ³ ---
    c1, c2 = st.columns([6, 1])
    with c1:
        st.subheader(f"â­ ãŠæ°—ã«å…¥ã‚Šï¼ˆ{len(st.session_state.favs)} ä»¶ï¼‰")
    with c2:
        if st.button("âŒ å…¨ã¦å¤–ã™", key="clear_favs_header", use_container_width=True):
            st.session_state.favs = set()
            st.rerun()

    # ãŠæ°—ã«å…¥ã‚Šä¸€è¦§ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ç„¡è¦–ã§å…¨ä½“ã‹ã‚‰ï¼‰ï¼‹ tags åˆ—ï¼ˆç·¨é›†å¯ï¼‰
    visible_cols_full = make_visible_cols(df)
    if "è‘—è€…" in visible_cols_full and "summary" in df.columns:
        idx = visible_cols_full.index("è‘—è€…")
        if "summary" not in visible_cols_full:
            visible_cols_full.insert(idx + 1, "summary")

    fav_disp_full = df.loc[:, visible_cols_full].copy()
    fav_disp_full["_row_id"] = fav_disp_full.apply(make_row_id, axis=1)
    fav_disp = fav_disp_full[fav_disp_full["_row_id"].isin(st.session_state.favs)].copy()

    # ãŠæ°—ã«å…¥ã‚Šè¡¨ç¤ºç”¨ã«ã‚‚ç™ºè¡Œå¹´ã®ã‚«ãƒ³ãƒã‚’é™¤å»
    if "ç™ºè¡Œå¹´" in fav_disp_full.columns:
        try:
            fav_disp_full["ç™ºè¡Œå¹´"] = fav_disp_full["ç™ºè¡Œå¹´"].astype(str).str.replace(",", "").str.strip()
        except Exception:
            pass

    def tags_str_for(rid: str) -> str:
        s = st.session_state.fav_tags.get(rid, set())
        return ", ".join(sorted(s)) if s else ""

    if not fav_disp.empty:
        # åˆ—åä¿®æ­£ï¼ˆé–‹å§‹ãƒšãƒ¼ã‚¸ â†’ p.å§‹ / çµ‚äº†ãƒšãƒ¼ã‚¸ â†’ p.çµ‚ï¼‰
        rename_map = {}
        if "é–‹å§‹ãƒšãƒ¼ã‚¸" in fav_disp.columns:
            rename_map["é–‹å§‹ãƒšãƒ¼ã‚¸"] = "p.å§‹"
        if "çµ‚äº†ãƒšãƒ¼ã‚¸" in fav_disp.columns:
            rename_map["çµ‚äº†ãƒšãƒ¼ã‚¸"] = "p.çµ‚"
        if rename_map:
            fav_disp = fav_disp.rename(columns=rename_map)

        fav_disp["â˜…"] = fav_disp["_row_id"].apply(lambda rid: rid in st.session_state.favs)
        fav_disp["tags"] = fav_disp["_row_id"].apply(tags_str_for)

        fav_column_config = {
            "â˜…": st.column_config.CheckboxColumn("â˜…", help="ãƒã‚§ãƒƒã‚¯ã§è§£é™¤/è¿½åŠ ï¼ˆä¸‹ã®ãƒœã‚¿ãƒ³ã§åæ˜ ï¼‰", default=True, width="small"),
            "tags": st.column_config.TextColumn("tagsï¼ˆã‚«ãƒ³ãƒ/ç©ºç™½åŒºåˆ‡ã‚Šï¼‰", help="ä¾‹: æ¸…é…’, ä¹³é…¸èŒ"),
        }
        if "HPãƒªãƒ³ã‚¯å…ˆ" in fav_disp.columns:
            fav_column_config["HPãƒªãƒ³ã‚¯å…ˆ"] = st.column_config.LinkColumn("HP", display_text="HP")
        if "PDFãƒªãƒ³ã‚¯å…ˆ" in fav_disp.columns:
            fav_column_config["PDFãƒªãƒ³ã‚¯å…ˆ"] = st.column_config.LinkColumn("PDF", display_text="PDF")

        # åˆ—é †èª¿æ•´ï¼šã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆé †ã«åˆã‚ã›ã‚‹
        desired_front = ["â˜…", "No.", "HPãƒªãƒ³ã‚¯å…ˆ", "PDFãƒªãƒ³ã‚¯å…ˆ", "ç™ºè¡Œå¹´", "å·»æ•°", "å·æ•°", "p.å§‹", "p.çµ‚"]
        front = [c for c in desired_front if c in fav_disp.columns]
        rest = [c for c in fav_disp.columns if c not in set(front) and c not in {"_row_id", "tags"}]
        fav_display_order = front + rest + ["tags", "_row_id"]

        with st.form("fav_table_form", clear_on_submit=False):
            fav_edited = st.data_editor(
                fav_disp[fav_display_order],
                key="fav_editor",
                use_container_width=True,
                hide_index=True,
                column_config=fav_column_config,
                disabled=[c for c in fav_display_order if c not in ["â˜…", "tags"]],
                height=420,
                num_rows="fixed",
            )
            apply_fav = st.form_submit_button("ãŠæ°—ã«å…¥ã‚Šã®å¤‰æ›´ï¼ˆâ˜…/tagsï¼‰ã‚’æ›´æ–°", use_container_width=True)

        if apply_fav:
            subset_ids_fav = set(fav_disp["_row_id"].tolist())
            fav_checked_subset = set(fav_edited.loc[fav_edited["â˜…"] == True, "_row_id"].tolist())
            st.session_state.favs = (st.session_state.favs - subset_ids_fav) | fav_checked_subset

            def parse_tags(s):
                if not isinstance(s, str): s = str(s or "")
                parts = [t.strip() for t in re.split(r"[ ,ï¼Œã€ï¼›;ã€€]+", s) if t.strip()]
                return set(parts)
            for _, r in fav_edited.iterrows():
                rid = r["_row_id"]
                tag_set = parse_tags(r.get("tags", ""))
                if tag_set:
                    st.session_state.fav_tags[rid] = tag_set
                elif rid in st.session_state.fav_tags:
                    del st.session_state.fav_tags[rid]

            st.success("ãŠæ°—ã«å…¥ã‚Šï¼ˆâ˜…/tagsï¼‰ã‚’åæ˜ ã—ã¾ã—ãŸ")
            st.rerun()
    else:
        st.info("ãŠæ°—ã«å…¥ã‚Šã¯æœªé¸æŠã§ã™ã€‚ä¸Šã®è¡¨ã®ã€â˜…ã€ã«ãƒã‚§ãƒƒã‚¯ã—ã¦ã‹ã‚‰åæ˜ ã—ã¦ãã ã•ã„ã€‚")
        fav_edited = None

    # -------------------- ã‚¿ã‚°ã§ãŠæ°—ã«å…¥ã‚Šã‚’çµã‚Šè¾¼ã¿ï¼ˆAND/ORï¼‰ --------------------
    with st.expander("ğŸ” ã‚¿ã‚°ã§ãŠæ°—ã«å…¥ã‚Šã‚’çµã‚Šè¾¼ã¿ï¼ˆAND/ORï¼‰", expanded=False):
        tag_query = st.text_input("ã‚¿ã‚°æ¤œç´¢ï¼ˆç©ºç™½/ã‚«ãƒ³ãƒã§è¤‡æ•°å¯ï¼‰", key="tag_query")
        tag_mode = st.radio("ä¸€è‡´æ¡ä»¶", ["OR", "AND"], index=0, horizontal=True, key="tag_mode")

        fav_disp_for_filter = fav_disp_full[fav_disp_full["_row_id"].isin(st.session_state.favs)].copy()
        if tag_query.strip():
            tags = [t.strip() for t in re.split(r"[ ,ï¼Œã€ï¼›;ã€€]+", tag_query) if t.strip()]
            def match_tags_row(row):
                row_tags = st.session_state.fav_tags.get(row["_row_id"], set())
                return all(t in row_tags for t in tags) if tag_mode == "AND" else any(t in row_tags for t in tags)
            fav_disp_for_filter = fav_disp_for_filter[fav_disp_for_filter.apply(match_tags_row, axis=1)]

        def tags_str_for_filter(rid: str) -> str:
            s = st.session_state.fav_tags.get(rid, set())
            return ", ".join(sorted(s)) if s else ""
        fav_disp_for_filter["tags"] = fav_disp_for_filter["_row_id"].apply(tags_str_for_filter)

        show_cols = ["No.","ç™ºè¡Œå¹´","å·»æ•°","å·æ•°","è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«","è‘—è€…","å¯¾è±¡ç‰©_top3","ç ”ç©¶ã‚¿ã‚¤ãƒ—","HPãƒªãƒ³ã‚¯å…ˆ","PDFãƒªãƒ³ã‚¯å…ˆ","tags"]
        show_cols = [c for c in show_cols if c in fav_disp_for_filter.columns]
        # ensure displayed year has no comma
        if "ç™ºè¡Œå¹´" in fav_disp_for_filter.columns:
            try:
                fav_disp_for_filter["ç™ºè¡Œå¹´"] = fav_disp_for_filter["ç™ºè¡Œå¹´"].astype(str).str.replace(",", "").str.strip()
            except Exception:
                pass
        st.dataframe(fav_disp_for_filter[show_cols], use_container_width=True, hide_index=True)

    # -------------------- ä¸‹éƒ¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆCSVå‡ºåŠ›ï¼š2ç¨®é¡ï¼‰ --------------------
    st.caption(
        f"ç¾åœ¨ã®ãŠæ°—ã«å…¥ã‚Šï¼š{len(st.session_state.favs)} ä»¶ / "
        f"ã‚¿ã‚°æ•°ï¼š{len({t for s in st.session_state.fav_tags.values() for t in s})} ç¨®"
    )

    filtered_export_df = disp.drop(columns=["â˜…", "_row_id"], errors="ignore")
    if "ç™ºè¡Œå¹´" in filtered_export_df.columns:
        try:
            filtered_export_df["ç™ºè¡Œå¹´"] = filtered_export_df["ç™ºè¡Œå¹´"].astype(str).str.replace(",", "").str.strip()
        except Exception:
            pass

    fav_export = fav_disp_full[fav_disp_full["_row_id"].isin(st.session_state.favs)].copy()
    def _tags_join(rid: str) -> str:
        s = st.session_state.fav_tags.get(rid, set())
        return ", ".join(sorted(s)) if s else ""
    fav_export["tags"] = fav_export["_row_id"].map(_tags_join)
    fav_export = fav_export.drop(columns=["_row_id"], errors="ignore")
    if "ç™ºè¡Œå¹´" in fav_export.columns:
        try:
            fav_export["ç™ºè¡Œå¹´"] = fav_export["ç™ºè¡Œå¹´"].astype(str).str.replace(",", "").str.strip()
        except Exception:
            pass

    c_dl1, c_dl2 = st.columns(2)
    with c_dl1:
        st.download_button(
            "ğŸ“¥ çµã‚Šè¾¼ã¿çµæœã‚’CSVå‡ºåŠ›ï¼ˆè¡¨ç¤ºåˆ—ã®ã¿ï¼‰",
            data=filtered_export_df.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"filtered_{time.strftime('%Y%m%d')}.csv",
            mime="text/csv",
            use_container_width=True
        )
    with c_dl2:
        st.download_button(
            "â­ ãŠæ°—ã«å…¥ã‚Šã‚’CSVå‡ºåŠ›ï¼ˆtagsä»˜ãï¼‰",
            data=fav_export.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"favorites_{time.strftime('%Y%m%d')}.csv",
            mime="text/csv",
            use_container_width=True,
            disabled=fav_export.empty
        )

with tab_analysis:
    render_analysis_tab(df, use_disk_cache=use_disk_cache)