from __future__ import annotations
import pandas as pd
import streamlit as st
from .base import norm_key, short_preview, PALETTE, get_banner_filters
from .compute import build_keyword_cooccur_edges
from .network import compute_node_communities_from_edges, draw_pyvis_from_edges
from .copyui import expander as copy_expander

def render_cooccur_block(df_use: pd.DataFrame) -> None:
    c1, c2, c3, c4, c5 = st.columns([1,1,1.6,1.6,0.9])
    with c2:
        min_edge = st.number_input("æœ€ä½å…±èµ·æ•°ï¼ˆåŒæ™‚å‡ºç¾ï¼‰", min_value=1, max_value=50, value=3, step=1, key="kw_co_minw")
    with c1:
        topN = st.number_input("è¡¨ç¤ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°", min_value=30, max_value=300, value=120, step=10, key="kw_co_topn")
    with c3:
        include_raw = st.text_input("å¿…é ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆéƒ¨åˆ†ä¸€è‡´ãƒ»ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰", value="", key="kw_co_include", placeholder="ä¾‹: é…µæ¯, ä¹³é…¸èŒ")
    with c4:
        exclude_raw = st.text_input("é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆéƒ¨åˆ†ä¸€è‡´ãƒ»ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰", value="", key="kw_co_exclude", placeholder="ä¾‹: è©¦é¨“, å®Ÿé¨“")
    with c5:
        st.markdown("<div style='height:32px'></div>", unsafe_allow_html=True)
        lcc_only = st.checkbox("ä¸»è¦ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã¿", value=False, key="kw_co_lcc_only")

    include_list = [norm_key(x) for x in _split(include_raw)]
    exclude_list = [norm_key(x) for x in _split(exclude_raw)]

    edges = build_keyword_cooccur_edges(df_use, int(min_edge))
    if not edges.empty and (include_list or exclude_list):
        def _contains_any(name: str, needles: list[str]) -> bool:
            s = norm_key(name)
            return any(n in s for n in needles)
        if include_list:
            mask_inc = edges["src"].astype(str).map(lambda v: _contains_any(v, include_list)) | \
                       edges["dst"].astype(str).map(lambda v: _contains_any(v, include_list))
            edges = edges[mask_inc]
        if not edges.empty and exclude_list:
            mask_exc = edges["src"].astype(str).map(lambda v: _contains_any(v, exclude_list)) | \
                       edges["dst"].astype(str).map(lambda v: _contains_any(v, exclude_list))
            edges = edges[~mask_exc]

    if not edges.empty and int(topN) > 0:
        deg = pd.concat([edges.groupby("src")["weight"].sum(), edges.groupby("dst")["weight"].sum()], axis=1).fillna(0).sum(axis=1)
        keep_nodes = set(deg.sort_values(ascending=False).head(int(topN)).index.tolist())
        edges = edges[edges["src"].isin(keep_nodes) & edges["dst"].isin(keep_nodes)].reset_index(drop=True)

    if lcc_only:
        try:
            import networkx as nx
            if not edges.empty:
                G_tmp = nx.Graph()
                for _, r in edges.iterrows(): G_tmp.add_edge(str(r["src"]), str(r["dst"]))
                if G_tmp.number_of_nodes()>0:
                    comps = list(nx.connected_components(G_tmp))
                    if comps:
                        lcc_nodes = set(max(comps, key=len))
                        edges = edges[edges["src"].astype(str).isin(lcc_nodes) & edges["dst"].astype(str).isin(lcc_nodes)].reset_index(drop=True)
        except Exception as e:
            st.info(f"LCC æŠ½å‡ºã§ä¾‹å¤–: {e}")

    st.caption(f"ã‚¨ãƒƒã‚¸æ•°: {len(edges)}")

    # Build and display co-occurrence edges table with cluster color and example titles
    comm_map = compute_node_communities_from_edges(edges)

    df_edges = edges.copy()
    def _edge_cluster_id(row):
        src_id = comm_map.get(str(row["src"]))
        dst_id = comm_map.get(str(row["dst"]))
        if src_id == dst_id and src_id is not None:
            return src_id
        if src_id is not None:
            return src_id
        if dst_id is not None:
            return dst_id
        return None
    df_edges["cluster_id"] = df_edges.apply(_edge_cluster_id, axis=1)

    cluster_img = df_edges["cluster_id"].map(lambda c: _color_square_data_uri(PALETTE[int(c) % len(PALETTE)]) if pd.notna(c) else "")
    df_edges["cluster_img"] = cluster_img

    df_edges = _attach_example_titles(df_use, df_edges, max_titles=3)

    show_df = df_edges[["cluster_img","src","dst","weight","example_titles"]].rename(columns={
        "cluster_img":"cluster",
        "src":"èªA",
        "dst":"èªB",
        "weight":"å…±èµ·å›æ•°",
        "example_titles":"è«–æ–‡ä¾‹"
    })

    st.dataframe(
        show_df.head(300),
        use_container_width=True,
        hide_index=True,
        column_config={
            "cluster": st.column_config.ImageColumn("cluster", help="è‡ªå‹•ã‚¯ãƒ©ã‚¹ã‚¿è‰²ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨åŒæœŸï¼‰ã€‚", width="small"),
            "èªA": st.column_config.TextColumn("èªA", width="small"),
            "èªB": st.column_config.TextColumn("èªB", width="small"),
            "å…±èµ·å›æ•°": st.column_config.NumberColumn("å…±èµ·å›æ•°", format="%d", width="small"),
            "è«–æ–‡ä¾‹": st.column_config.TextColumn("è«–æ–‡ä¾‹", help="ãã®ãƒšã‚¢ãŒåŒæ™‚ã«ç™»å ´ã—ãŸè«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«ã®ä¾‹ï¼ˆæœ€å¤§3ä»¶ï¼‰", width="large"),
        }
    )

    # ã‚¯ãƒ©ã‚¹ã‚¿å‡¡ä¾‹ï¼ˆè¡¨ã§ãªã chips ã ã‘ï¼‰
    if comm_map:
        nodes_present = set(df_edges["src"].astype(str)).union(set(df_edges["dst"].astype(str)))
        counts = {}
        for n in nodes_present:
            cid = comm_map.get(str(n))
            if isinstance(cid, int): counts[cid] = counts.get(cid, 0) + 1
        chips = []
        for cid in sorted(counts.keys()):
            col = PALETTE[cid % len(PALETTE)]
            chips.append(f"<span style='display:inline-block;width:10px;height:10px;border-radius:2px;background:{col};margin:0 6px 0 0;vertical-align:middle;'></span> C{cid+1}ï¼ˆ{counts[cid]}èªï¼‰")
        st.markdown("**ã‚¯ãƒ©ã‚¹ã‚¿å‡¡ä¾‹**&nbsp;&nbsp;" + " ".join(chips), unsafe_allow_html=True)

    # æ¡ä»¶ã‚µãƒãƒªãƒ¼ï¼ˆæœŸé–“ã®å³ã« å¯¾è±¡ç‰©ãƒ»ç ”ç©¶ã‚¿ã‚¤ãƒ— ã‚’è¿½åŠ ï¼‰
    _inc_pv = short_preview(include_list, 3)
    _exc_pv = short_preview(exclude_list, 3)
    y_from, y_to, tg_sel, tp_sel = get_banner_filters(prefix="kw")
    period = f"{int(y_from)}â€“{int(y_to)}" if (y_from is not None and y_to is not None) else "â€”"
    tg_preview = short_preview(tg_sel or [], 3)
    tp_preview = short_preview(tp_sel or [], 3)

    parts = [f"è¡¨ç¤ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°{int(topN)}", f"æœ€ä½å…±èµ·æ•°â‰§{int(min_edge)}"]
    if lcc_only:
        parts.append("ä¸»è¦ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã¿")
    if _inc_pv:
        parts.append(f"å¿…é ˆï¼š{_inc_pv}")
    if _exc_pv:
        parts.append(f"é™¤å¤–ï¼š{_exc_pv}")
    parts.append(f"æœŸé–“ï¼š{period}")
    if tg_preview:
        parts.append(f"å¯¾è±¡ç‰©ï¼š{tg_preview}")
    if tp_preview:
        parts.append(f"ç ”ç©¶ã‚¿ã‚¤ãƒ—ï¼š{tp_preview}")
    st.caption(" ï½œ ".join(parts))

    # ã‚³ãƒ”ãƒ¼UIï¼ˆãƒãƒ¼ãƒ‰åï¼‰
    nodes = sorted(set(df_edges["src"].astype(str)).union(set(df_edges["dst"].astype(str)))) if not df_edges.empty else []
    copy_expander("ğŸ“‹ ãƒãƒ¼ãƒ‰åã‚’ã™ãã‚³ãƒ”ãƒ¼", nodes)

    with st.expander("ğŸ•¸ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å¯è¦–åŒ–", expanded=False):
        freeze_layout = st.checkbox("ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’å›ºå®š", value=True, key="kw_co_freeze")
        if st.button("ğŸŒ æç”»ã™ã‚‹", key="kw_co_draw"):
            draw_pyvis_from_edges(edges, height_px=680, freeze_layout=freeze_layout)
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã®ç›´ä¸‹ã«ã‚‚åŒã˜æ¡ä»¶ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
            _inc_pv = short_preview(include_list, 3)
            _exc_pv = short_preview(exclude_list, 3)
            y_from, y_to, tg_sel, tp_sel = get_banner_filters(prefix="kw")
            period = f"{int(y_from)}â€“{int(y_to)}" if (y_from is not None and y_to is not None) else "â€”"
            tg_preview = short_preview(tg_sel or [], 3)
            tp_preview = short_preview(tp_sel or [], 3)
            _parts_draw = [f"è¡¨ç¤ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°{int(topN)}", f"æœ€ä½å…±èµ·æ•°â‰§{int(min_edge)}"]
            if lcc_only:
                _parts_draw.append("ä¸»è¦ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã¿")
            if _inc_pv:
                _parts_draw.append(f"å¿…é ˆï¼š{_inc_pv}")
            if _exc_pv:
                _parts_draw.append(f"é™¤å¤–ï¼š{_exc_pv}")
            _parts_draw.append(f"æœŸé–“ï¼š{period}")
            if tg_preview:
                _parts_draw.append(f"å¯¾è±¡ç‰©ï¼š{tg_preview}")
            if tp_preview:
                _parts_draw.append(f"ç ”ç©¶ã‚¿ã‚¤ãƒ—ï¼š{tp_preview}")
            st.caption(" ï½œ ".join(_parts_draw))

def _attach_example_titles(df_src: pd.DataFrame, edges: pd.DataFrame, max_titles: int = 3) -> pd.DataFrame:
    # Columns to try for titles
    title_columns = [
        "ã‚¿ã‚¤ãƒˆãƒ«","è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«","è«–æ–‡å","é¡Œå","title","Title","Japanese Title","English Title",
        "title_ja","title_en","ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆå’Œï¼‰","ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆè‹±ï¼‰","å’Œæ–‡ã‚¿ã‚¤ãƒˆãƒ«","è‹±æ–‡ã‚¿ã‚¤ãƒˆãƒ«"
    ]
    available_cols = [col for col in title_columns if col in df_src.columns]

    # Columns to try for keywords
    keyword_columns = [
        "llm_keywords", "primary_keywords", "secondary_keywords", "featured_keywords"
    ] + [f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰{i}" for i in range(1,11)]

    # Extract keywords sets from df_src rows
    # Use _split and norm_key for tokens
    def extract_keywords_from_row(row) -> set[str]:
        kw_set = set()
        for col in keyword_columns:
            if col in df_src.columns:
                val = row.get(col)
                if isinstance(val, str) and val.strip():
                    kw_set.update(norm_key(k) for k in _split(val))
        return kw_set

    # Build list of (keyword_set, title)
    kw_title_list = []
    for _, row in df_src.iterrows():
        # Find first available title column with non-empty string
        title = None
        for col in available_cols:
            val = row.get(col)
            if isinstance(val, str) and val.strip():
                title = val.strip()
                break
        if not title:
            continue
        kw_set = extract_keywords_from_row(row)
        if not kw_set:
            continue
        kw_title_list.append((kw_set, title))

    # For each edge, find up to max_titles titles where both src and dst in kw_set
    example_titles = []
    for _, row in edges.iterrows():
        src = norm_key(str(row["src"]))
        dst = norm_key(str(row["dst"]))
        matched_titles = []
        for kw_set, title in kw_title_list:
            if src in kw_set and dst in kw_set:
                matched_titles.append(title)
                if len(matched_titles) >= max_titles:
                    break
        example_titles.append(" ï¼ ".join(matched_titles))
    edges = edges.copy()
    edges["example_titles"] = example_titles
    return edges

def _color_square_data_uri(hex_color: str, size: int = 12) -> str:
    svg = f"""<svg xmlns="http://www.w3.org/2000/svg" width="{size}" height="{size}">
<rect width="{size}" height="{size}" fill="{hex_color}"/>
</svg>"""
    import base64
    b64 = base64.b64encode(svg.encode("utf-8")).decode("ascii")
    return f"data:image/svg+xml;base64,{b64}"

def _split(s: str) -> list[str]:
    import re
    return [w.strip() for w in re.split(r"[,;ï¼›ã€ï¼Œ/ï¼|ï½œ\sã€€]+", str(s or "")) if w.strip()]